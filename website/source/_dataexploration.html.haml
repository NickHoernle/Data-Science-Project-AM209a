%p The Yelp Challenge dataset is very high-dimensional and split across multiple distinct categories. We chose to focus on just users, businesses without their photos, and reviews without their associated text, though we did a little bit of exploration and brainstorming about text and images. Although the data came fairly cleanly packaged, we did decide to <a href='https://github.com/NickHoernle/Data-Science-Project-AM209a/blob/master/util/dump_yelp_data.py'>convert it</a> from a nested JSON structure to a flat CSV structure suitable for use in <a href='http://pandas.pydata.org'>pandas</a> (which we used extensively), and wrote several common scripts to <a href='https://github.com/NickHoernle/Data-Science-Project-AM209a/blob/master/util/load_yelp_data.py'>load</a> and <a href='https://github.com/NickHoernle/Data-Science-Project-AM209a/blob/master/data_exploration/time_augment_reviews.py'>augment</a> the data with useful location and time-based features.

.wrapper_col.clearfix
  .left
    %p The topics we investigated in data exploration can be subdivided into <strong><a href='#data-exp-base-line'>general exploration</a></strong>, <strong><a href='#data-exp-loc-based'>location based analysis</a></strong>, <strong><a href='#networks'>network analysis</a></strong> and <strong><a href='#data-exp-time-based'>time based analysis</a></strong>.
    %p After investigating the entire dataset, which spans 10 cities around the globe, we chose to focus our investigation on restaurants and bars in Phoenix, Arizona. The dataset contains many "one review" users (i.e. users that only submit one review); these cases are particularly hard to make predictions for due to a lack of user history. While it is true that Yelp users will occasionally travel between cities, we wanted to limit the scope of our analysis to some subset where there was likely to be a greater overlap between businesses rated by users (i.e. hone the analysis in on one city). Additionally, we chose to limit our study to restaurants and bars as it's more conceivable that users will share preferences within a single category rather than across categories. After limiting the dataset in this manner, the sparsity of the dataset decreased by about an order of magnitude.

  .right
    %strong Restaurants in Phoenix, Arizona Yelp Dataset
    <iframe width="900" height="350" frameborder="0" scrolling="no" src="images/map.html"></iframe>

%section#data-exp-base-line
  %h3 Baseline Analysis

  The full dataset contains 2,700,000 reviews from 687,000 users for 86,000 businesses. The business dataset consists of 15 features including category of business (e.g., fast food, restaurant, nightlife, etc.), full address, operation hours, latitude, longitude, review count, and stars earned. We augmented it to include the city. The user dataset consists of 11 features including average stars, compliments, elite, number of fans, friend IDs, name, review count, vote categories, and when they started Yelping.

  .wrapper_col.clearfix
    .right
      = image_tag('images/skewed_data_log.png')
    .left
      %strong How is the data distributed?
      %p Both the user and business data is highly right skewed. Most users rate only a small number of businesses, and similarly, the majority of businesses receive a comparatively small number of reviews, though less extremely so than users. The implications of this observation for us is that using a particular user's review history to predict that user's rating for any one particular business is likely to be unfruitful (the small user history will prevail for the majority of cases). We run this analysis in <a href='#linear'>Interpretable Linear Models</a> and we see that while including a user's review history does add a useful predictor, it does not dramatically improve the general prediction for most users. However, we did find that once we <a href='#matrices-min-reviews'>limited the dataset</a> to users with at least a few reviews, our accuracy improved significantly.

  .wrapper_col.clearfix
    .right
      = image_tag('images/rating-standard-deviations.png')
    .left
      %strong How varied are the ratings?
      %p
        Users tend to rate businesses highly with the ratings between 4 and 5 consisting of a total of 67% of all of the entered reviews in the system. In agreement with this, the users also typically tend to give many similar reviews, as we see that the majority of users have a very small range in the number of stars that they give. In contrast to this, we see that businesses tend to receive a large range of reviews. This speaks to the preferences of individuals  - what works for one person might not work for another. The key learning here is that since users tend not to deviate from their review, we can possibly bias a model by using a user's mean rating to that point in time (the caveat here is that this data must exist as noted in the point above). It is also important to note that using a business's mean score may be a poor predictor for individual user's ratings due to the variation in these ratings.

  .wrapper_col.clearfix
    %strong What are the best restaurants in Phoenix?
    / =image_tag('score_with_prior_assumption.png')
    %p Having decided to explore the culinary experience in Phoenix, and inspired by the homework assignment on movie reviews, we wanted to understand the scope for the best and worst ratings. The problem here is that a restaurant that receives few reviews may have a disproportionately unrepresentative sample. Therefore, considering only the raw business rating would lead to an unreliable result. Similarly, considering only the number of reviews is unintuitive as a business with many low scores cannot be considered a 'good' restaurant. To resolve these issues, we treated our knowledge about the quality of a restaurant probabalistically, modeling our belief in its ranking (from 0 as bad to 1 as great) as a Beta distribution initially centered at 0.5. We treated 5-star reviews as upvotes and 1-star reviews as downvotes, with values in between counting to some degree as both up and downvotes (a technique we applied somewhat successfully again <a href='#baselines-beta-prior'>later</a>). A few examples of the rankings that method generated are given in the tables below:

  %h4 The Highest-Ranked 5 Restaurants in Phoenix
  %table.table.table-bordered.table-striped
    %thead
      %tr
        %th Name
        %th Categories
        %th Review Count
        %th Avg. Stars
    <tbody>
    <tr>
    <td>Little Miss BBQ</td>
    <td>Barbeque, Restaurants</td>
    <td>944</td>
    <td>4.794</td>
    </tr>
    <tr>
    <td>El New Yorican Central Catering &amp; Delivery</td>
    <td>Puerto Rican, Spanish, Caribbean, Restaurants</td>
    <td>139</td>
    <td>4.855</td>
    </tr>
    <tr>
    <td>Top Marks Cafe</td>
    <td>Food, Gelato, Coffee &amp; Tea, Creperies</td>
    <td>33</td>
    <td>5.000</td>
    </tr>
    <tr>
    <td>The Local Press Sandwich Bar</td>
    <td>Sandwiches, Restaurants</td>
    <td>47</td>
    <td>4.974</td>
    </tr>
    <tr>
    <td>Tacos Chiwas</td>
    <td>Mexican, Restaurants</td>
    <td>89</td>
    <td>4.915</td>
    </tr>
    </tbody>

  %h4 The Lowest-Ranked 5 Restaurants in Phoenix
  %table.table.table-bordered.table-striped
    %thead
      %tr
        %th Name
        %th Categories
        %th Review Count
        %th Avg. Stars
    <tbody>
    <tr>
    <td>Dairy Queen</td>
    <td>Fast Food, Restaurants</td>
    <td>33</td>
    <td>1.280</td>
    </tr>
    <tr>
    <td>Pizza Hut</td>
    <td>Italian, Pizza, Chicken Wings, Restaurants</td>
    <td>7</td>
    <td>1.000</td>
    </tr>
    <tr>
    <td>KFC</td>
    <td>Fast Food, Chicken Wings, Restaurants</td>
    <td>13</td>
    <td>1.154</td>
    </tr>
    <tr>
    <td>McDonald's</td>
    <td>Burgers, Fast Food, Restaurants</td>
    <td>18</td>
    <td>1.313</td>
    </tr>
    <tr>
    <td>Far East Asian Fire</td>
    <td>Chicken Shop, Asian Fusion, Restaurants</td>
    <td>25</td>
    <td>1.211</td>
    </tr>
    </tbody>
